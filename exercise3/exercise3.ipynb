{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets work on Real World Data Problems\n",
    "\n",
    "In this notebook, we will work on real world problems and try to eliminate problems like\n",
    "\n",
    "- Outliers\n",
    "- Clusters\n",
    "- Empty Data Cells\n",
    "\n",
    "These problems must be eliminated from a data set to properly analyse it and get the best possible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "install.packages(c(\"tidyverse\", \"patchwork\", \"statip\", \"glue\"))\n",
    "\n",
    "# Import the packages\n",
    "library(tidyverse)\n",
    "library(patchworkd)\n",
    "library(statip)\n",
    "library(glue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Previous Model on StudyHours\n",
    "\n",
    "In this piece of code we will be testing the same model for distribution we created in Exercise #02 and try to extract data based on `Grades` then on `StudyHours` this time and let's see what results do we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import data from the source\n",
    "students <- read.csv(file = \"https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/grades.csv\")\n",
    "\n",
    "# remove the records with no data in them\n",
    "students <- students %>% drop_na()\n",
    "\n",
    "# Add a column of pass or fail\n",
    "students <- students %>% \n",
    "  mutate(Status = if_else(Grade >= 60, \"PASS\", \"FAIL\"))\n",
    "\n",
    "# distribution function\n",
    "show_distribution <- function (data, binwidth) {\n",
    "\n",
    "  # get all measures of centeral tendancies\n",
    "  # get all measures of centeral tendancies\n",
    "  data_min <- min(pull(data))\n",
    "  data_max <- max(pull(data))\n",
    "  data_mean <- mean(pull(data))\n",
    "  data_median <- median(pull(data))\n",
    "  data_mode <- mfv(pull(data))\n",
    "\n",
    "  # print the values\n",
    "  stats <- glue(\n",
    "    'Minimum: {format(round(data_min, 2), nsmall = 2)}\n",
    "     Maximum: {format(round(data_max, 2), nsmall = 2)}\n",
    "     Median: {format(round(data_median, 2), nsmall = 2)}\n",
    "     Mode: {format(round(data_mode, 2), nsmall = 2)}\n",
    "     Mean: {format(round(data_mean, 2), nsmall = 2)}'\n",
    "  )\n",
    "\n",
    "  # ploting historgram based on given data set\n",
    "  histogram <- ggplot(data) +\n",
    "    geom_histogram(mapping = aes(x = pull(data)),\n",
    "      binwidth = binwidth, fill = \"midnightblue\", alpha = 0.7, boundary = 0.4) + \n",
    "\n",
    "  # Adding line for measures of centeral tendancy\n",
    "  geom_vline(xintercept = data_min, color = \"gray33\", linetype = \"dashed\", size = 1.0) +\n",
    "  geom_vline(xintercept = data_max, color = \"gray33\", linetype = \"dashed\", size = 1.0) +\n",
    "  geom_vline(xintercept = data_mode, color = \"green\", linetype = \"dashed\", size = 1.0) +\n",
    "  geom_vline(xintercept = data_median, color = \"blue\", linetype = \"dashed\", size = 1.0) +\n",
    "  geom_vline(xintercept = data_mean, color = \"red\", linetype = \"dashed\", size = 1.0) +\n",
    "\n",
    "  # Adding titles and legends\n",
    "  ggtitle(\"Data Distribution\") +\n",
    "  xlab(\"\") +\n",
    "  ylab(\"Frequency\") +\n",
    "\n",
    "  # adjusting the title position on the graph\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 20))\n",
    "\n",
    "  # Lets plot the box plot graph now\n",
    "  box_plot <- ggplot(data) +\n",
    "    geom_boxplot(mapping = aes(x = pull(data), y = 1), \n",
    "      fill = \"yellow\", color = \"gray33\") + \n",
    "\n",
    "  # Lets now add titles and labels to this graph\n",
    "  ggtitle(\"Box Plot\") +\n",
    "  xlab(\"Value\") +\n",
    "  ylab(\"\") +\n",
    "  \n",
    "  # adjust title properties\n",
    "  theme(plot.title = element_text(hjust = 0.5, size = 20))\n",
    "\n",
    "  return (\n",
    "    list(\n",
    "      stats, histogram, box_plot\n",
    "    )\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets remove the outlier\n",
    "\n",
    "We'll attempt to remove the outlier by removing all the students with studyhours less than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Getting students with study Hours greater than 1\n",
    "col <- students %>%\n",
    "  select(StudyHours) %>%\n",
    "  filter(StudyHours > 1)\n",
    "\n",
    "# calling the function with new refined data\n",
    "show_distribution(col, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's work on 99 Percentile\n",
    "\n",
    "In this piece of code, we'll be attempting to remove the students which are at the bottom with 1% percentile and work on the rest of the data. This can be acheived using the quantile function available in stats library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1% quantile\n",
    "q01 <- students %>%\n",
    "  pull(StudyHours) %>%\n",
    "  quantile(1/100, names = FALSE)\n",
    "\n",
    "# getting students with 99% percentile\n",
    "col <- students %>%\n",
    "  select(StudyHours) %>%\n",
    "  filter(StudyHours > q01)\n",
    "\n",
    "# calling the function with new refined data\n",
    "show_distribution(col, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the Density Graph\n",
    "\n",
    "We can use the previous model of density graph to visualize the data and see that most our data trend lies near 8-10 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that returns a density plot\n",
    "show_density <- function(var_data) {\n",
    "  \n",
    "  # Get statistics\n",
    "  mean_val <- mean(pull(var_data))\n",
    "  med_val <- median(pull(var_data))\n",
    "  mod_val <- statip::mfv(pull(var_data))\n",
    "  \n",
    "  \n",
    "  # Plot the density plot\n",
    "  density_plot <- ggplot(data = var_data) +\n",
    "  geom_density(aes(x = pull(var_data)), fill=\"orangered\", color=\"white\", alpha=0.4) +\n",
    "    \n",
    "  # Add lines for the statistics\n",
    "  geom_vline(xintercept = mean_val, color = 'cyan', linetype = \"dashed\", size = 1.3) +\n",
    "  geom_vline(xintercept = med_val, color = 'red', linetype = \"dashed\", size = 1.3 ) +\n",
    "  geom_vline(xintercept = mod_val, color = 'yellow', linetype = \"dashed\", size = 1.3 ) +\n",
    "    \n",
    "  # Add titles and labels\n",
    "  ggtitle('Data Density') +\n",
    "  xlab('') +\n",
    "  ylab('Density') +\n",
    "  theme(plot.title = element_text(hjust = 0.5),\n",
    "        axis.text.x = element_text(size = 20),\n",
    "        axis.text.y = element_text(size = 20))\n",
    "  \n",
    "  return(density_plot) # End of returned outputs\n",
    "  \n",
    "} # End of function\n",
    "\n",
    "# 1% quantile\n",
    "q01 <- students %>%\n",
    "  pull(StudyHours) %>%\n",
    "  quantile(1/100, names = FALSE)\n",
    "\n",
    "# getting students with 99% percentile\n",
    "col <- students %>%\n",
    "  select(StudyHours) %>%\n",
    "  filter(StudyHours > q01)\n",
    "\n",
    "# Get the density of StudyHours\n",
    "show_density(var_data = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets's get Measure of Variance\n",
    "\n",
    "Measure of variance basically helps us understand how much data is variating.\n",
    "\n",
    "__Range__: The difference between the maximum and minimum. There's no built-in function for this, but it's easy to calculate by using the min and max functions. Another approach would be to use Base R's base::range() which returns a vector containing the minimum and maximum of all the given arguments. Wrapping this in base::diff() will get you well on your way to finding the range.\n",
    "\n",
    "__Variance__: The average of the squared difference from the mean. You can use the built-in var function to find this.\n",
    "\n",
    "__Standard deviation__: The square root of the variance. You can use the built-in sd function to find this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the columns on which Variance is to be calculated\n",
    "cols <- students %>%\n",
    "  select(Grade, StudyHours)\n",
    "\n",
    "# Map function works like any language's map function\n",
    "map(cols, function(column) {\n",
    "  range <- max(column) - min(column)\n",
    "  variance <- var(column)\n",
    "  std <- sd(column)\n",
    "\n",
    "  glue('\n",
    "  Range: {format(round(range, 2), nsmall = 2)}\n",
    "  Variance: {format(round(variance, 2), nsmall = 2)}\n",
    "  Standard Deviation: {format(round(std, 2), nsmall = 2)}\n",
    "  ', .sep = '\\n')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the standard deviation, the more variance there is when you compare values in the distribution with the distribution mean. That is, the data is more spread out.\n",
    "\n",
    "When you're working with a normal distribution, the standard deviation works with the particular characteristics of a normal distribution to provide even greater insight. This can be summarized by using the 68–95–99.7 rule, also known as the empirical rule, which is described as follows:\n",
    "\n",
    "In any normal distribution:\n",
    "\n",
    "- Approximately 68.26 percent of values fall within one standard deviation from the mean.\n",
    "- Approximately 95.45 percent of values fall within two standard deviations from the mean.\n",
    "- Approximately 99.73 percent of values fall within three standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# use this function to quickly evaluate a data set\n",
    "summary(students)\n",
    "\n",
    "# this library does descriptive analysis on your data\n",
    "library(summarytools)\n",
    "\n",
    "# gives lots of details like mean, media, etc.\n",
    "descr(students, stats = \"common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's examine boxplot\n",
    "\n",
    "In this point of this notebook, we are going to attempt to learn more deeply about the boxplot graphs and see how they help us greatly in understanding the data trend and how we can learn quickly about the students in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# getting the 1% percentile\n",
    "q01 <- students %>%\n",
    "  pull(StudyHours) %>%\n",
    "  quantile(1/100, name = FALSE)\n",
    "\n",
    "# filtering and removing the outliers using 1 percentile\n",
    "col <- students %>%\n",
    "  select(StudyHours) %>%\n",
    "  filter(StudyHours > q01)\n",
    "\n",
    "# plotting the boxplot chart\n",
    "students %>%\n",
    "  ggplot() +\n",
    "  geom_boxplot(mapping = aes(x = Status, y = StudyHours), fill = \"yellow\", alpha = 0.4) +\n",
    "\n",
    "# adding our own custom number of data labels on y axis\n",
    "scale_y_continuous(limits = c(0,16), breaks = seq(0, 16, by = 1)) +\n",
    "\n",
    "# adding titles and labels\n",
    "ggtitle(\"Box Plot\") +\n",
    "theme(axis.text.x = element_text(size = 20),\n",
    "      axis.text.y = element_text(size = 20),\n",
    "      plot.title = element_text(hjust = 0.5, size = 20),\n",
    "      panel.grid.major.y = element_line(colour = \"gray33\", linetype = \"dashed\", linewidth = 0.5),\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](Assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's pivot the table\n",
    "\n",
    "We can use the pivot_longer function in R to pivot the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pivot data from wide to long\n",
    "df_sample_long <- students %>%\n",
    "\n",
    "  # Select all except the Status\n",
    "  select(!Status) %>% \n",
    "\n",
    "  # Pivot all except the Name column\n",
    "  pivot_longer(!Name names_to = \"Metrics\", values_to = \"Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used to check the relationship between two properties and you can read it like this:\n",
    "\n",
    "- If it is close to 1, it means they are strongly related such that if one increases the other increases as well\n",
    "- If it is close to -1, it means they are strongly negatively related such that if one increases the other decreases.\n",
    "- If it is close to 0 then the two properties are not closely related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Correlation coefficient as\n",
    "cor(students$StudyHours, students$Grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get the Linear Equation for our data\n",
    "\n",
    "We can use the linear regression model to predict the student's scores, or perhaps use the same model on other data set to extract meaningful information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract tables to apply the linear regression\n",
    "regression <- students %>%\n",
    "  select(Grade, StudyHours)\n",
    "\n",
    "# Apply the linear model\n",
    "linear <- lm(Grade ~ StudyHours, data = regression)\n",
    "\n",
    "# extract the values from it\n",
    "intercept_c <- linear$coefficients[1]\n",
    "slope_m <- linear$coefficients[2]\n",
    "\n",
    "# print out the data\n",
    "glue('\n",
    "  slope: {format(round(slope_m, 4), nsmall = 4)}\n",
    "  y-intercept: {format(round(intercept_c, 4), nsmall = 4)}\n",
    "  f(x) = {format(round(slope_m, 4), nsmall = 4)}x + {format(round(intercept_c, 4), nsmall = 4)}\n",
    "')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Now lets use the above model to calculate linear regression for everyone\n",
    "df_regression <- df_regression %>%\n",
    "  mutate(fx = (slope_m * Grade + intercept_c), error = (fx - Grade))\n",
    "\n",
    "# And plot it as\n",
    "df_regression %>% \n",
    "  ggplot() +\n",
    "  geom_point(aes(x = StudyHours, y = Grade)) +\n",
    "  # Add a line based on the linear model\n",
    "  geom_abline(intercept = intercept_c, slope = slope_m, color = \"springgreen3\", size = 1) +\n",
    "  ggtitle('Study Time vs Grade') +\n",
    "  theme(plot.title = element_text(hjust = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](Assets/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model to predict student score\n",
    "\n",
    "With this given model below and the sample data given to us, we have devised a linear model that can help us calculate a student's grade based on their study hours. But remember we are only using this linear model because we found our `correlation coefficient` near to 1 which means study hours and grades and very closely related to eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# it returns the grade based on previous slope_m and intercept_c calculations\n",
    "predict_grade <- function (study_hours) {\n",
    "  return (slope_m * study_hours + intercept_c)\n",
    "} # end of function\n",
    "\n",
    "# prints the result making sure it does not get less than 0 or greater than 100\n",
    "max(0, min(100, predict_grade(17)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
